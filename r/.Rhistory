#========================================================#
##
# REPEAT SALES INDEX ESTIMATION#
# #
##
# © Thies Lindenthal#
# thilin@mit.edu#
# <all rights reserved>	#
##
# 2012-11-21#
# #
# This software is work in progress and #
# comes without any warranty.#
# #
# --- As a background, the following papers are helpful ---#
#  - Martin J. Bailey, Richard F. Muth, Hugh O. Nourse (1963). "A Regression Method for Real Estate Price Index Construction". Journal of the American Statistical Association, Vol. 58, Iss. 304.#
#  - Case, K., & Shiller, R. (1987). "Prices of single family homes since 1970: New indexes for four cities". NewEngland Economic Review: 45–56, Sept./Oct.#
#  - Bokhari, S., & Geltner, D. (2012). "Estimating real estate price movements for high frequency tradable indexes in a scarce data environment". The Journal of Real Estate Finance and Economics, 1-22.#
#  - Bryan, T., & Colwell, P. (1982). "Housing price indices". In C. F. Sirmans (Ed.), Research in real estate(Vol. 2). Greenwich: JAI Press.#
#========================================================#
#
# =============== SETTINGS ==============================#
settings<-list()#
settings[['path_data']] <- "/Users/thies/git/research/openindex/data/input.csv"#
settings[['output_directory']] <- "/Users/thies/git/research/openindex/output/"#
# Index update frequency (in months)#
settings[['index_frequency']] <- 1#
# Base Frequency for Frequency Conversion (Bokhari/Geltner methodology), in months#
settings[['conversion_base_frequency']]<-24#
settings[['repeat_sales_return_interval']] <- c(1/3,3)#
settings[['repeat_sales_date_min']] <- as.Date("1980-01-01")#
settings[['repeat_sales_date_max']] <- as.Date("2006-01-31")#
# Minimum of days that need to pass between transactions of the same asset#
# This reduces effect of fast home swaps#
settings[['min_days_between_repeat_sales']] <- 60#
# ===============================================#
#
# ==== Load libraries#
library(MASS) #
source("/Users/thies/git/research/openindex/R/openindex_includes.R")#
#
#
# ==== LOAD DATA#
# Expected input: CSV sheet containing information on:#
#     - Property identifier. ID can be a number or a set of strings or a combination of both.#
#     - Sales price#
#     - Date of sale. Format: yyyy-mm-dd#
# An example can be found at http://lindenthal.eu/sales_sample.csv#
sales <- read.csv(settings[['path_data']],as.is=TRUE)#
colnames(sales)<-c("id","price","date")#
# order by date, ascending#
sales$date<-as.Date(sales$date)#
sales<-sales[order(sales$date),]#
# Year, quarter and month of sale#
sales$year<-format(sales$date,format("%Y"))#
sales$quarter<-paste(sales$year,rep("-Q",nrow(sales)),ceiling(as.numeric(format(sales$date,format("%m")))/3), sep="")#
sales$month<-format(sales$date,format("%Y-%m"))#
# apply date filters#
if(!is.na(settings[['repeat_sales_date_min']])){#
	sales<-subset(sales, date >= settings[['repeat_sales_date_min']])#
}	#
if(!is.na(settings[['repeat_sales_date_max']])){#
	 sales<-subset(sales, date <= settings[['repeat_sales_date_max']])#
	}#
# Set interval markers#
months<-seq(from=settings[['repeat_sales_date_min']], to=settings[['repeat_sales_date_max']], by="month")#
intervals<-months[seq(1, length(months), settings[['index_frequency']])]#
sales$interval<-1#
for(i in 2:length(intervals)){#
	sales$interval[sales$date >= intervals[i]]<-i#
}#
intervals_base<-months[seq(1, length(months), settings[['conversion_base_frequency']])]#
sales$interval_base<-1#
for(i in 2:length(intervals_base)){#
	sales$interval_base[sales$date >= intervals_base[i]]<-i#
}#
#
#
#
# ======== SUMMARY STATISTICS SALES =============#
# summary statistics for the sales#
sumstats<-summary(sales[,2:3])#
print("SUMMARY STATISTICS FOR SALES")#
print(sumstats)#
write.csv(sumstats,file=paste(settings[['output_directory']],"sumstats.csv", sep="/"), quote=FALSE, row.names=FALSE)#
# create histograms for sales prices and sales date#
png(file=paste(settings[['output_directory']],'hist_sales_prices.png', sep=""), bg="white")#
hist(sales$price, breaks=100, main="Histogram Sales Prices", col="lightblue")#
box()#
dev.off()#
png(file=paste(settings[['output_directory']],'hist_sales_date.png', sep=""), bg="white")#
hist(sales$date, breaks=length(intervals), main="Histogram Sales Prices", col="lightblue")#
box()#
dev.off()#
#==========================#
#
#
#
#
#=========== FIND REPEAT SALES ===============#
pairs<-merge(sales, sales, by="id")#
pairs<-subset(pairs,date.x < date.y)#
# calculate return between sales#
pairs$return<-pairs$price.y/pairs$price.x#
pairs$ln_return <- log(pairs$return)#
topreturns<-subset(pairs,return > quantile(pairs$return, 0.99))#
topreturns<-topreturns[rev(order(topreturns$return)),]#
lowreturns<-subset(pairs,return < quantile(pairs$return, 0.01))#
lowreturns<-lowreturns[order(lowreturns$return),]#
# write lists of top-/low-returns to output#
write.csv(lowreturns,file=paste(settings[['output_directory']],"pairs_return_high.csv", sep="/"), quote=FALSE, row.names=FALSE)#
write.csv(topreturns,file=paste(settings[['output_directory']],"pairs_return_low.csv", sep="/"), quote=FALSE, row.names=FALSE)#
# histogram of returns#
png(file=paste(settings[['output_directory']],'hist_repeats_returns.png', sep=""), bg="white")#
hist(pairs$return, breaks=100, main="Histogram Repeat Sales Returns (uncensored)", col="lightblue", border=FALSE)#
box()#
dev.off()#
# Exclude repeat sales with unreasonably high returns (cut-offs defined in settings )#
pairs<-subset(pairs, return >= settings[['repeat_sales_return_interval']][1] & return <= settings[['repeat_sales_return_interval']][2])#
# Exclude sales where houses were resold very quickly#
pairs<-subset(pairs, as.numeric(date.y-date.x) > settings[['min_days_between_repeat_sales']])#
#
# histogram of returns#
png(file=paste(settings[['output_directory']],'hist_repeats_returns_censored.png', sep=""), bg="white")#
hist(pairs$return, breaks=100, main="Histogram Repeat Sales Returns (censored)", col="lightblue", border=FALSE)#
box()#
dev.off()#
#
# Overview of pairs per interval#
tab1<-as.data.frame(table(pairs$interval.x), stringsAsFactors=FALSE)#
tab2<-as.data.frame(table(pairs$interval.y), stringsAsFactors=FALSE)#
tab<-merge(tab1,tab2,by="Var1", all=TRUE)#
colnames(tab)<-c("interval","first_sale","repeat_sale")#
tab<-tab[order(tab$interval),]#
# summary statistics of#
summary(tab)#
# counts per month for pairs#
write.csv(tab,file=paste(settings[['output_directory']],"pairs_per_interval.csv", sep=""), quote=FALSE, row.names=FALSE)#
png(file=paste(settings[['output_directory']],'pairs_per_interval.png', sep=""), bg="white")#
barplot(t(tab[,2:3]), beside=TRUE, col=c("blue","green"), border=FALSE)#
legend("topleft",c("first sale","repeat sale"),fil=c("blue","green"))#
box()#
dev.off()#
#
#
# ======= BASIC OVERVIEW#
# compare straight index to mean sales prices and median sales prices#
y<- c(0,estimate_index(pairs,intervals))#
for(n in 2:length(y)){#
	y[n]<-y[n-1]+y[n]#
}#
y<-exp(y)*100#
x<-intervals[1:length(y)]#
means<-as.matrix(tapply(sales$price, sales$interval, mean))#
means<-means/means[1]*100#
medians<-as.matrix(tapply(sales$price, sales$interval, median))#
medians<-medians/medians[1]*100#
# Make graph of comparison#
png(file=paste(settings[['output_directory']],'repeatsalesindex_mean_median.png', sep=""), bg="white")#
plot(x,y, main=paste("Direct repeat sales index vs Means vs Median (interval: ",settings[['index_frequency']]," months)", sep=""), ylab=paste(format(settings[['repeat_sales_date_min']], format="%Y-%m"),"= 100%"), xlab="Time", type="n")#
lines(x,y)#
lines(x,means[1:length(x)],col="red")#
lines(x,medians[1:length(x)],col="blue")#
box()#
legend("topleft",c("repeat sales index","red","median"), lwd=1, col=c("black","red","blue"))#
dev.off()#
#==================#
#
#
#
#
# ============== FREQUENCY CONVERSION / LOW TO HIGH FREQUENCY ==================#
# See Bokhari and Geltner (2011) for background on two-stage estimation#
indices<-list()#
conversion_ratio<-settings[['conversion_base_frequency']]/settings[['index_frequency']]#
for(i in 1:conversion_ratio){#
	# shift dates by one frequency#
	intervals_base_shifted <- months[seq((i-1)*settings[['index_frequency']] +1, length(months), settings[['conversion_base_frequency']])]#
	# and estimate shifted index#
	indices[[i]]<-estimate_index(pairs, intervals_base_shifted)	#
}#
# visualize the shifted indices (for debugging)#
plot(range(0:length(indices[[1]])*conversion_ratio),c(0.5,1.8), type="n")#
annualplots<-matrix(NA, conversion_ratio,(length(indices[[1]])*conversion_ratio))#
for (i in 1:conversion_ratio){#
	index<-cumsum(indices[[i]])#
	k <- i#
	for (j in 1:length(index)){#
		annualplots[i,k]<-index[j]#
		k<-k+conversion_ratio#
	}#
	line<-as.data.frame(rbind(1:ncol(annualplots), annualplots[i,]))#
	line<-line[,!is.na(line[2,])]#
	lines(line[1,], exp(line[2,]), col="grey")#
}#
# create matrix of stacked returns#
# this will be input for second stage of estimation#
stacked_ret<-matrix(0,nrow=length(indices[[1]])*conversion_ratio,ncol=((length(indices[[1]])+1)* conversion_ratio))#
for(i in 1:length(indices[[1]])){#
	for (j in 1:conversion_ratio){#
		ii <- (i-1)*conversion_ratio +j#
		stacked_ret[ii,1]<-indices[[j]][i]#
		stacked_ret[ii,(ii+1):(ii+ conversion_ratio)]<-rep(1, conversion_ratio)#
	}		#
}	#
stacked_ret<-stacked_ret[!is.na(stacked_ret[,1]),]#
X<-stacked_ret[,2:ncol(stacked_ret)]#
# calculate generalized inverse of matrix#
Xginv<-ginv(X)#
# calculate the monthly return coefficients (b)#
b<-Xginv%*%stacked_ret[,1]#
# convert monthly returns to cumulative returns#
b_added<-cumsum(b)#
index<-as.data.frame(exp(c(0,b_added[1:(length(intervals)-1)]))*100)#
colnames(index)<-"estimate"#
index$date<-intervals#
# create plot#
plot(intervals,index$estimate,xlab="",ylab=paste(settings[['repeat_sales_date_min']],"= 100%"), type="n")#
lines(intervals, index$estimate)#
write.csv(index,file=paste(settings[['output_directory']],"index.csv", sep="/"), quote=FALSE, row.names=FALSE)
